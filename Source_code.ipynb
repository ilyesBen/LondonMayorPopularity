{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import random\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model, svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "##nltk.download('stopwords')\n",
    "##nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twiiter API Ahthentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "#Register a Twitter App and add the authentication and authorisation below to be able to use tweepy\n",
    "\n",
    "consumer_key = 'fake_consumer_key' \n",
    "consumer_secret = 'fake_consumer_secret'\n",
    "access_token = 'fake_access_token'\n",
    "access_secret = 'fake_access_secret'\n",
    " \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction (training set)\n",
    "The emojis  :D  :)  :-)  :-D  has been queried to represnt positive tweets \n",
    "\n",
    "The emojis  :(  :'(  ;-(  ;(  has been queried to represnt negative tweets\n",
    "\n",
    "refer to figure 1 of [19]\n",
    "\n",
    "We queried tweets in London with a radius of 200 Km. refer to [22] for geocode parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the tweets in a file in Json format\n",
    "with open('training_set_Lodon.json', 'a') as f :\n",
    "    for tweet in tweepy.Cursor(api.search, q=\";(\",rpp=100, lang=\"en\", geocode=\"51.507351,-0.127758,200Km\").items(5000):\n",
    "        f.write(json.dumps(tweet._json) + '\\n')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# read positive tweets\n",
    "with open('training_set_London.json', 'r') as f :\n",
    "    training_tweets_positive = [json.loads(line)['text'] for line in f]\n",
    "\n",
    "#read negative tweets\n",
    "with open('training_set_London_neg.json', 'r') as f :\n",
    "    training_tweets_negative = [json.loads(line)['text'] for line in f]\n",
    "\n",
    "# mergre the two categories in one String\n",
    "all_tweets = [' '.join(training_tweets_positive + training_tweets_negative)]\n",
    "\n",
    "# create the object CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# tokenize and build vocabulary\n",
    "vectorizer.fit(all_tweets)\n",
    "\n",
    "# encode document\n",
    "vector = vectorizer.transform(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words' vocabulary are sorted ascendingly with respect to their Ids (values in the dictionary)\n",
    "# We get a list of tuples sorted\n",
    "sorted_vocabulary = sorted(vectorizer.vocabulary_.items(), key=operator.itemgetter(1))\n",
    "#Convert to list by taking only the words\n",
    "vocabulary = [value for (value,key) in sorted_vocabulary]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1177dd7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "n, bins, patches = plt.hist(vocabulary[:1000], weights = vector.toarray()[0][:1000], facecolor='green', bins=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing and preparation\n",
    "\n",
    "This part is devided into two parts : \n",
    "\n",
    "1. data cleaning for Naive bayes classifier :\n",
    "We remove the Stop words, links, hashtags, user tags, punctuations and all words with a lenght smaller than 2, because for this classifer will be based on the most apearing words and these words apear frequently but they are meaningless in terms of sentiment analysis\n",
    "\n",
    "\n",
    "2. data cleaning for SVM and logistic regression :\n",
    "these classifiers use tfidf technique for features weightening which will remove the most apearing words automatically (more explanation in the report). hence we will remove only the hastags users' tags.\n",
    "\n",
    "The 'clean' function allows us to clean the dataset depeding on each case by changing the parameters :\n",
    "\n",
    "* stop_words = True => remove Stop words\n",
    "* hashtags = list of hastags  => remove hashtags from tweet\n",
    "* user_mentions = list users' tag = > remove users' tag from tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "STOP_WORDS.update(['https','http','RT','...'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(tweetText,stop_words = True, hashtags=None, user_mentions=None):\n",
    "    black_list = [] ## append haghtags and user tags to remove them\n",
    "    \n",
    "    if hashtags != None:\n",
    "        for hasch in hashtags:\n",
    "             black_list.append(hasch['text'])\n",
    "    \n",
    "    if (user_mentions != None and user_mentions != []):\n",
    "        for user in user_mentions:\n",
    "            black_list.append(user['screen_name'])\n",
    "    \n",
    "    text_tokenised = word_tokenize(tweetText) # list of lists of words\n",
    "    tweet_cleaned = []\n",
    "    \n",
    "    if stop_words :\n",
    "        for word in text_tokenised:\n",
    "            if (word not in black_list) and ('//' not in word) and (len(word) > 2) and (word not in STOP_WORDS):\n",
    "                tweet_cleaned.append(word)\n",
    "    else : \n",
    "        for word in text_tokenised:\n",
    "            if (word not in black_list) and ('//' not in word) and (len(word) > 2) :\n",
    "                tweet_cleaned.append(word)\n",
    "        \n",
    "    \n",
    "    return tweet_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning for SVM and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and clean positive tweets from file \n",
    "with open('training_set_London.json', 'r') as f :\n",
    "     tweets_positive = [' '.join( clean(json.loads(line)[\"text\"], False, json.loads(line)[\"entities\"][\"hashtags\"], json.loads(line)['entities']['user_mentions']) ) for line in f]\n",
    "\n",
    "#read and clean negative tweets from file\n",
    "with open('training_set_London_neg.json', 'r') as f :\n",
    "     tweets_negative = [' '.join(clean(json.loads(line)[\"text\"],False, \n",
    "                                json.loads(line)[\"entities\"][\"hashtags\"],\n",
    "                                json.loads(line)['entities']['user_mentions'])) for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning for Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract negative and postive tweet's text, clean them and label them and create a list of all words cleaned for further usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "\n",
    "with open('training_set_London.json', 'r') as f :\n",
    "    training_pos_tweets = [( ' '.join(clean(json.loads(line)[\"text\"], True, json.loads(line)[\"entities\"][\"hashtags\"],json.loads(line)['entities']['user_mentions'])) , 'pos') for line in f]\n",
    "\n",
    "with open('training_set_London.json', 'r') as f :\n",
    "    for line in f:\n",
    "        all_words.extend(clean(json.loads(line)[\"text\"], True))\n",
    "\n",
    "with open('training_set_London_neg.json', 'r') as f :\n",
    "    training_neg_tweets = [(' '.join(clean(json.loads(line)[\"text\"], True, json.loads(line)[\"entities\"][\"hashtags\"],json.loads(line)['entities']['user_mentions'])), 'neg') for line in f]\n",
    "\n",
    "with open('training_set_London_neg.json', 'r') as f :  \n",
    "    for line in f:   \n",
    "        all_words.extend(clean(json.loads(line)[\"text\"], True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Tfidf technique to encode tweets (as expalained before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tweets = tweets_negative + tweets_positive # regroup all the tweets \n",
    "\n",
    "vectorizer = TfidfVectorizer() # Create the vectorizer Object\n",
    "vectorizer.fit(training_tweets)#  create the voacabulary with weigths from tweets \n",
    "\n",
    "\n",
    "vector = vectorizer.transform(training_tweets) # assign weights for each word of the tweets \n",
    "\n",
    "target = np.append(np.zeros(len(tweets_negative), dtype=int) , np.ones(len(tweets_positive), dtype=int)) #Create the target with two categoris (0 for negative and 1 for postive)\n",
    "\n",
    "# Split the data into training test and testing test\n",
    "x_train, x_test, y_train, y_test = train_test_split(vector.toarray(), target, test_size=0.20, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the logistic regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7586397873283119"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "logreg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics to assess the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.70      0.73      4145\n",
      "          1       0.76      0.80      0.78      4883\n",
      "\n",
      "avg / total       0.76      0.76      0.76      9028\n",
      "\n",
      "[[2920 1225]\n",
      " [ 954 3929]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, logreg.predict(x_test)))\n",
    "print(metrics.confusion_matrix(y_test, logreg.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Tfidf for this model as well, so we take the previous results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train) > len(x_train[0]) # n_samples > n_features => put dual = False (reference : http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.777027027027027"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.LinearSVC(C=1, penalty ='l1', dual = False ) \n",
    "svc.fit(x_train, y_train)\n",
    "svc.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.74      0.75      4145\n",
      "          1       0.79      0.80      0.80      4883\n",
      "\n",
      "avg / total       0.78      0.78      0.78      9028\n",
      "\n",
      "[[3088 1057]\n",
      " [ 956 3927]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, svc.predict(x_test)))\n",
    "print(metrics.confusion_matrix(y_test, svc.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a features extractor function that check whether a word apears in a document or not, the classifier will be based on the features extracted from the tweets by this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document, word_feature):\n",
    "    document_words = set(clean(document))\n",
    "    features = {}\n",
    "    for word in word_feature:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we use the list fo all words computed previously and take the 2000 most frequent worded sorted by frequency from the less apearing to the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordFreq = nltk.FreqDist(w.lower() for w in all_words)  ## calculate the frequency of apearance of each word in all the documents\n",
    "WordFreq_sorted = sorted(WordFreq.items(), key=operator.itemgetter(1)) ## Sort the words with their corresponding frequency from the lowest to the highest\n",
    "word_feature_tuple = WordFreq_sorted[len(WordFreq_sorted)-2000:] ## take the 2000 most apearing words \n",
    "word_feature = [c for (c,n) in word_feature_tuple] ## Convert to a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset for the training and the testing respecting the format of the nltk library which means all the features extracted taged with a label ('pos' for positive and 'neg' for negative in our case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = training_pos_tweets + training_neg_tweets\n",
    "random.shuffle(document) # shuffle the documents to make the training roughly equitable between the two categories\n",
    "featuresets = [(document_features(d,word_feature), c) for (d,c) in document]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the feature set into training set and testing set and train the classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6785555555555556\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = featuresets[9000:], featuresets[:9000] ## split the dataSet into training set and testing set\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set) ## Train our Naive Bayes classifier\n",
    "print(nltk.classify.accuracy(classifier, test_set)) ## accuracy of the model based on the test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple function that classify a tweet based on the last Naive classifer trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyNaive(tweet, word_feature):\n",
    "    return classifier.classify(document_features(tweet, word_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.72      0.51      0.59      3271\n",
      "        pos       0.66      0.83      0.73      3729\n",
      "\n",
      "avg / total       0.69      0.68      0.67      7000\n",
      "\n",
      "[[1658 1613]\n",
      " [ 645 3084]]\n"
     ]
    }
   ],
   "source": [
    "naive_prediction = [classifyNaive(tweet[0], word_feature) for tweet in document[:7000]] #predictions of the classifier\n",
    "naive_ground_truth = [tweet[1] for tweet in document[:7000]] #The ground Truth\n",
    "\n",
    "print(metrics.classification_report(naive_ground_truth, naive_prediction))\n",
    "print(metrics.confusion_matrix(naive_ground_truth, naive_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the most 10 Informative features the Naive bayes classifier was based on to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "        contains(hoseok) = True              neg : pos    =    158.6 : 1.0\n",
      "        contains(vocals) = True              neg : pos    =    109.1 : 1.0\n",
      "         contains(condo) = True              pos : neg    =     62.6 : 1.0\n",
      "           contains(llâ€¦) = True              neg : pos    =     60.5 : 1.0\n",
      "      contains(taehyung) = True              neg : pos    =     59.9 : 1.0\n",
      "        contains(rushed) = True              pos : neg    =     57.1 : 1.0\n",
      "    contains(normalised) = True              pos : neg    =     49.8 : 1.0\n",
      "       contains(scumbag) = True              pos : neg    =     49.8 : 1.0\n",
      "    contains(devastated) = True              neg : pos    =     39.6 : 1.0\n",
      "          contains(jump) = True              pos : neg    =     38.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Neutral tweets \n",
    "\n",
    "We noticed that there are some tweets thats does not carry any polarity (they are neutral regarding the subject), these tweets will be classified as positive or negative which decreases the credibiity and the accuracy of our models.\n",
    "\n",
    "We decided to remove alle the tweets considered as neutral before traning the models. To do that we the vader method available in the nltk library. The sentiment Intensity analyzer gives us the intensity of polarity and neutrality of text, we remove only the tweets that are considred as 100% neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. For TfIdf :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20898 24241\n",
      "16151 18799\n"
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "print(len(tweets_negative) , len(tweets_positive))\n",
    "\n",
    "for tweet in tweets_negative:\n",
    "    if sid.polarity_scores(tweet)['neu'] == 1.0:\n",
    "        tweets_negative.remove(tweet)\n",
    "\n",
    "for tweet in tweets_positive:\n",
    "    if sid.polarity_scores(tweet)['neu'] == 1.0:\n",
    "        tweets_positive.remove(tweet)\n",
    "\n",
    "print(len(tweets_negative) , len(tweets_positive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For Naive Bayes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20898 24241\n",
      "16188 18987\n"
     ]
    }
   ],
   "source": [
    "print(len(training_neg_tweets) , len(training_pos_tweets))\n",
    "\n",
    "for tweet in training_neg_tweets:\n",
    "    if sid.polarity_scores(tweet[0])['neu'] == 1.0:\n",
    "        training_neg_tweets.remove(tweet)\n",
    "\n",
    "for tweet in training_pos_tweets:\n",
    "    if sid.polarity_scores(tweet[0])['neu'] == 1.0:\n",
    "        training_pos_tweets.remove(tweet)\n",
    "\n",
    "print(len(training_neg_tweets) , len(training_pos_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the models without Neutral tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same steps done previously to train the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7886981402002862"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_tweets = tweets_negative + tweets_positive\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(training_tweets)\n",
    "vector = vectorizer.transform(training_tweets)\n",
    "\n",
    "target = np.append(np.zeros(len(tweets_negative), dtype=int) , np.ones(len(tweets_positive), dtype=int))\n",
    "x_train, x_test, y_train, y_test = train_test_split(vector.toarray(), target, test_size=0.20, random_state=0)\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=20, penalty='l1')\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "logreg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.76      0.77      3233\n",
      "          1       0.80      0.82      0.81      3757\n",
      "\n",
      "avg / total       0.79      0.79      0.79      6990\n",
      "\n",
      "[[2450  783]\n",
      " [ 693 3064]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, logreg.predict(x_test)))\n",
    "print(metrics.confusion_matrix(y_test, logreg.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SVM :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train) > len(x_train[0]) # n_samples > n_features => put dual = False (reference : http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7839771101573677"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.LinearSVC(C=10, penalty ='l1', dual = False ) \n",
    "svc.fit(x_train, y_train)\n",
    "svc.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.75      0.76      3233\n",
      "          1       0.79      0.81      0.80      3757\n",
      "\n",
      "avg / total       0.78      0.78      0.78      6990\n",
      "\n",
      "[[2437  796]\n",
      " [ 714 3043]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, svc.predict(x_test)))\n",
    "print(metrics.confusion_matrix(y_test, svc.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Naive Bayes Classifier :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-create the list of all words and the document containing all the tweets (positives and negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "document = training_neg_tweets + training_pos_tweets\n",
    "random.shuffle(document)\n",
    "for tweet in document:\n",
    "    all_words.extend(word_tokenize(tweet[0]))  # the function word_tokenise provided by the Nltk library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6911428571428572\n"
     ]
    }
   ],
   "source": [
    "WordFreq = nltk.FreqDist(w.lower() for w in all_words)  \n",
    "WordFreq_sorted = sorted(WordFreq.items(), key=operator.itemgetter(1)) \n",
    "word_feature_tuple = WordFreq_sorted[len(WordFreq_sorted)-2000:]  \n",
    "word_feature = [c for (c,n) in word_feature_tuple]\n",
    "featuresets = [(document_features(d,word_feature), c) for (d,c) in document]\n",
    "train_set, test_set = featuresets[7000:], featuresets[:7000] # take 20% for testing set\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set) \n",
    "print(nltk.classify.accuracy(classifier, test_set)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.73      0.52      0.61      3240\n",
      "        pos       0.67      0.83      0.74      3760\n",
      "\n",
      "avg / total       0.70      0.69      0.68      7000\n",
      "\n",
      "[[1699 1541]\n",
      " [ 621 3139]]\n"
     ]
    }
   ],
   "source": [
    "naive_prediction = [classifyNaive(tweet[0], word_feature) for tweet in document[:7000]]\n",
    "naive_ground_truth = [tweet[1] for tweet in document[:7000]]\n",
    "\n",
    "print(metrics.classification_report(naive_ground_truth, naive_prediction))\n",
    "print(metrics.confusion_matrix(naive_ground_truth, naive_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the models with Nltk samples\n",
    "\n",
    "The nltk library provides sample tweets for traning already defined as positive and negative (5000 for each category), we will use them to train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of tweets  for Tfidf (we don't clean because we don't have acess to user mentions and hashtags and we don't want to remove Stop words for Tfidf)\n",
    "training_tweets = twitter_samples.strings('negative_tweets.json') + twitter_samples.strings('positive_tweets.json')\n",
    "\n",
    "# Create a list of tweets cleaned and labelled with positive and negative for Naive Bayes Classifier\n",
    "document = [(' '.join(clean(tweet)),'neg') for tweet in twitter_samples.strings('negative_tweets.json')] + [(' '.join(clean(tweet)),'pos') for tweet in twitter_samples.strings('positive_tweets.json')]\n",
    "random.shuffle(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Neutral tweets :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Logistic Regression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.716"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(training_tweets)\n",
    "vector = vectorizer.transform(training_tweets)\n",
    "\n",
    "target = np.append(np.zeros(5000, dtype=int) , np.ones(5000, dtype=int))\n",
    "x_train, x_test, y_train, y_test = train_test_split(vector.toarray(), target, test_size=0.80, random_state=0)\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=20, penalty='l1')\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "logreg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.81      0.77       988\n",
      "          1       0.79      0.72      0.75      1012\n",
      "\n",
      "avg / total       0.76      0.76      0.76      2000\n",
      "\n",
      "[[796 192]\n",
      " [285 727]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, logreg.predict(x_test)))\n",
    "print(metrics.confusion_matrix(y_test, logreg.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train) > len(x_train[0]) # n_samples < n_features => put dual = True (reference : http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.727875"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.LinearSVC(C=1, penalty ='l2', dual = True) \n",
    "svc.fit(x_train, y_train)\n",
    "svc.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.77      0.74      3994\n",
      "          1       0.75      0.69      0.72      4006\n",
      "\n",
      "avg / total       0.73      0.73      0.73      8000\n",
      "\n",
      "[[3062  932]\n",
      " [1245 2761]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, svc.predict(x_test)))\n",
    "print(metrics.confusion_matrix(y_test, svc.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for tweet in document:\n",
    "    all_words.extend(word_tokenize(tweet[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703\n"
     ]
    }
   ],
   "source": [
    "WordFreq = nltk.FreqDist(w.lower() for w in all_words)  \n",
    "WordFreq_sorted = sorted(WordFreq.items(), key=operator.itemgetter(1)) \n",
    "word_feature_tuple = WordFreq_sorted[len(WordFreq_sorted)-2000:]  \n",
    "word_feature = [c for (c,n) in word_feature_tuple]\n",
    "featuresets = [(document_features(d,word_feature), c) for (d,c) in document]\n",
    "train_set, test_set = featuresets[2000:], featuresets[:2000] \n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set) \n",
    "print(nltk.classify.accuracy(classifier, test_set)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.75      0.63      0.68      1023\n",
      "        pos       0.67      0.78      0.72       977\n",
      "\n",
      "avg / total       0.71      0.70      0.70      2000\n",
      "\n",
      "[[641 382]\n",
      " [212 765]]\n"
     ]
    }
   ],
   "source": [
    "naive_prediction = [classifyNaive(tweet[0], word_feature) for tweet in document[:2000]]\n",
    "naive_ground_truth = [tweet[1] for tweet in document[:2000]]\n",
    "\n",
    "print(metrics.classification_report(naive_ground_truth, naive_prediction))\n",
    "print(metrics.confusion_matrix(naive_ground_truth, naive_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Neutral tweets :\n",
    "\n",
    "Remove neutral tweets from Nltk's tweets for both Naive Bayes and Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "9465\n",
      "10000\n",
      "7467\n"
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "negative_lenght = 5000\n",
    "positive_lenght = 5000\n",
    "\n",
    "print(len(training_tweets))\n",
    "\n",
    "for tweet in training_tweets[:5000]:\n",
    "    if sid.polarity_scores(tweet)['neu'] == 1.0:\n",
    "        negative_lenght = negative_lenght - 1\n",
    "        training_tweets.remove(tweet)\n",
    "\n",
    "for tweet in training_tweets[negative_lenght:]:\n",
    "    if sid.polarity_scores(tweet)['neu'] == 1.0:\n",
    "        positive_lenght = positive_lenght - 1\n",
    "        training_tweets.remove(tweet) \n",
    "\n",
    "print(len(training_tweets))\n",
    "\n",
    "print(len(document))\n",
    "\n",
    "for tweet in document:\n",
    "    if sid.polarity_scores(tweet[0])['neu'] == 1.0:\n",
    "        document.remove(tweet)\n",
    "\n",
    "print(len(document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Logistic Regression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7543581616481775"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(training_tweets)\n",
    "vector = vectorizer.transform(training_tweets)\n",
    "\n",
    "target = np.append(np.zeros(negative_lenght, dtype=int), np.ones(positive_lenght, dtype=int))\n",
    "x_train, x_test, y_train, y_test = train_test_split(vector.toarray(), target, test_size=0.20, random_state=0)\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1, penalty='l1')\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "logreg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.78      0.77       934\n",
      "          1       0.78      0.75      0.76       959\n",
      "\n",
      "avg / total       0.76      0.76      0.76      1893\n",
      "\n",
      "[[730 204]\n",
      " [242 717]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, logreg.predict(x_test)))\n",
    "print(metrics.confusion_matrix(y_test, logreg.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7617538298996303"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.LinearSVC(C=1, penalty ='l2', dual = True) \n",
    "svc.fit(x_train, y_train)\n",
    "svc.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.78      0.76       934\n",
      "          1       0.78      0.74      0.76       959\n",
      "\n",
      "avg / total       0.76      0.76      0.76      1893\n",
      "\n",
      "[[732 202]\n",
      " [249 710]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, svc.predict(x_test)))\n",
    "print(metrics.confusion_matrix(y_test, svc.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for tweet in document:\n",
    "    all_words.extend(word_tokenize(tweet[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7225\n"
     ]
    }
   ],
   "source": [
    "WordFreq = nltk.FreqDist(w.lower() for w in all_words)  \n",
    "WordFreq_sorted = sorted(WordFreq.items(), key=operator.itemgetter(1)) \n",
    "word_feature_tuple = WordFreq_sorted[len(WordFreq_sorted)-2000:]  \n",
    "word_feature = [c for (c,n) in word_feature_tuple]\n",
    "featuresets = [(document_features(d,word_feature), c) for (d,c) in document]\n",
    "train_set, test_set = featuresets[2000:], featuresets[:2000] \n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set) \n",
    "print(nltk.classify.accuracy(classifier, test_set)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.74      0.66      0.70       979\n",
      "        pos       0.71      0.78      0.74      1021\n",
      "\n",
      "avg / total       0.72      0.72      0.72      2000\n",
      "\n",
      "[[649 330]\n",
      " [225 796]]\n"
     ]
    }
   ],
   "source": [
    "naive_prediction = [classifyNaive(tweet[0], word_feature) for tweet in document[:2000]]\n",
    "naive_ground_truth = [tweet[1] for tweet in document[:2000]]\n",
    "\n",
    "print(metrics.classification_report(naive_ground_truth, naive_prediction))\n",
    "print(metrics.confusion_matrix(naive_ground_truth, naive_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the model for data classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the tweets in a file \n",
    "with open('SadiqKhan.json', 'a') as f :\n",
    "    for tweet in tweepy.Cursor(api.search, q=\"#SadiqKhan\",since=\"2018-04-10\",until= \"2018-04-11\",rpp=100, lang=\"en\").items():\n",
    "        f.write(json.dumps(tweet._json) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the tweets and clean them for Tfidf to apply the model on them\n",
    "with open('SadiqKhan.json', 'r') as f :\n",
    "    tweets_final = [' '.join( clean(json.loads(line)[\"text\"], False, json.loads(line)[\"entities\"][\"hashtags\"], json.loads(line)['entities']['user_mentions']) ) for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove neutral tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13068\n",
      "11566\n"
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "print(len(tweets_final))\n",
    "\n",
    "for tweet in tweets_final:\n",
    "    if sid.polarity_scores(tweet)['neu'] == 1.0:\n",
    "        tweets_final.remove(tweet)\n",
    "\n",
    "print(len(tweets_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the tweets with same format as the model chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_final = vectorizer.transform(tweets_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the predicstions (classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used Logistic regression (C=20, penalty='l1') with our tweets after  removing Neutral tweets because this is the model that gave the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_pos = 0\n",
    "number_neg = 0\n",
    "\n",
    "predictions = logreg.predict(vector_final)\n",
    "\n",
    "for predict in predictions:\n",
    "    if predict == 0:\n",
    "        number_neg+=1\n",
    "    else:\n",
    "        number_pos+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a12183470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(2)\n",
    "\n",
    "sentiments = [100*number_pos/(number_pos+number_neg), 100*number_neg/(number_pos+number_neg)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "pos, neg = plt.bar(x, sentiments)\n",
    "pos.set_facecolor('g')\n",
    "neg.set_facecolor('r')\n",
    "ax.set_ylim([0, 100])\n",
    "ax.set_ylabel('Percentage',fontsize=20)\n",
    "ax.set_title(\"London's Mayor Popularity\",fontsize=20)\n",
    "plt.xticks(x, ('positive', 'negative'),fontsize=20)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('pop.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6093, 5473)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_neg,number_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
